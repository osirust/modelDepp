# modelDepp
Этот репозиторий содержит код для решения задачи Deepfake Detection (Yandex ML Intensive). Текущий лучший результат (Private LB): > 0,9 .

Требования

    • Python: 3.10+
    
    • GPU: NVIDIA с поддержкой CUDA (рекомендуется 12GB+ VRAM, протестировано на RTX 4090/A100).
    
    • Библиотеки:
    
Bash

pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
pip install kornia facenet-pytorch pandas numpy opencv-python tqdm scikit-learn


Инструкция по запуску (Pipeline)

Весь процесс разбит на 3 этапа для надежности: Подготовка данных -> SSL Претрейн -> Финальное обучение.

Шаг 1: Подготовка данных (Face Alignment)

Вырезаем лица и приводим к разрешению 384x384. Скрипт использует MTCNN с "умным кропом" (fallback на центр, если лицо не найдено).

Bash

python align_faces.py

    • Вход: data/dataset/train_images, data/dataset/test_images
    
    • Выход: data/faces_512/train, data/faces_512/test
    
    • Время: ~1-2 часа.
    
Шаг 2: Генерация псевдо-лейблов (Mining Diamonds)

Используем ансамбль предыдущей версии (V38) для разметки тестовых данных с высокой уверенностью (threshold > 0.995).

Bash

python make_diamonds.py

    • Выход: train_diamond.csv (расширенный датасет, ~58k изображений).
    
    • Время: ~5 минут.
    
Шаг 3: Основное обучение (The Boss)

Запускает Self-Supervised Learning (SimMIM) на 50 эпох, затем файнтюнинг классификатора на 5 фолдов.

Bash

python train_v42_diamond.py

    • Конфигурация: img_size=512, batch_size=8 (virt=32), ssl_epochs=50.
    
    • Время: ~12-15 часов (SSL + 5 Folds).
    
    • Результат: submission_v42.csv и веса моделей.
    

Эссе: Эволюция архитектур для детекции дипфейков

Тема: Сравнительный анализ эффективности легковесных и специализированных архитектур в задаче бинарной классификации дипфейков.
Введение
Задача обнаружения дипфейков характеризуется высокой сложностью из-за тонких артефактов генерации, которые часто невидимы человеческому глазу. В рамках соревнования было проведено исследование двух подходов: использование модифицированной легковесной архитектуры (MobileNetV2Simple) и тяжелой специализированной системы (EfficientNet+FPN+CBAM), что в итоге привело к созданию финального решения TitanNet V42.
1. Базовый уровень: MobileNetV2Simple
На начальном этапе эксперименты проводились с модифицированной версией MobileNetV2. Главным преимуществом этого подхода была скорость: обучение занимало всего 3.5 минуты на эпоху.
Однако результаты оказались неудовлетворительными:
    • Низкое качество: Лучший F1-score составил всего 0.3572.
    • Нестабильность: Наблюдалась обратная зависимость между точностью (Precision) и полнотой (Recall). При попытке повысить Recall до 0.70, Precision падал до 0.18.
    • Критическая ошибка: Модель пропустила 36.5% фейков (465 изображений из 1275).
Вывод: Легковесные архитектуры без специализированных механизмов внимания не способны уловить высокочастотные артефакты дипфейков, «сваливаясь» в предсказание мажоритарного класса (реальных лиц).
2. Прорыв: EfficientNet + FPN + CBAM
Для решения проблем базовой модели была разработана архитектура, включающая:
    1. Backbone: EfficientNet-B3.
    2. FPN (Feature Pyramid Network): Для анализа признаков на разных масштабах.
    3. CBAM (Convolutional Block Attention Module): Для пространственного и канального внимания к аномалиям.
Результаты показали качественный скачок:
    • F1-score: Вырос до 0.8921 (улучшение на 149.7%).
    • Надежность: Количество пропущенных фейков сократилось до 4.9% (всего 63 изображения).
    • Стабильность: Обучение проходило плавно, без коллапсов.
Платой за качество стало время обучения: оно увеличилось до 37.5 минут на эпоху (в 10.7 раз дольше). Однако для задач безопасности такие затраты полностью оправданы.
3. Финал: TitanNet V42 (Diamond)
Опираясь на успех механизмов внимания, мы перешли к архитектуре TitanNet (модифицированный ConvNeXt V2) с разрешением 512x512. Ключевые улучшения:
    • SSL Pretraining (SimMIM): Модель обучалась восстанавливать скрытые части лиц, выучивая геометрию лица без учителя.
    • Pseudo-Labeling: Добавление ~8000 "алмазных" примеров из теста с уверенностью >99.5%.
    • Результат: Это позволило пробить потолок 0.90 и достичь 0.95816 на лидерборде.
Заключение
Исследование подтвердило, что универсальные архитектуры (MobileNet) непригодны для надежной детекции дипфейков. Инвестиции в вычислительные ресурсы (переход на EfficientNet/TitanNet, увеличение разрешения до 512px) и специализированные методы (Attention, SSL) дают экспоненциальный прирост качества, превращая систему из "генератора случайных чисел" в надежный инструмент безопасности.

Список файлов проекта
Убедись, что все эти файлы находятся в корневой директории перед запуском:
1. Скрипты (Код):
    • align_faces.py — Скрипт для нарезки лиц (MTCNN).
    • make_diamonds.py — Скрипт для генерации псевдо-лейблов (использует старые веса).
    • train_v42_diamond.py — Главный скрипт обучения (SSL + Classification + Inference).
    • plot_training_curves.py — (Опционально) Для визуализации графиков обучения.
    • safe_inference.py — (Опционально) Запасной скрипт для инференса, если основной упадет.
2. Данные:
    • data/dataset/train_images/ — Оригинальные фото (трейн).
    • data/dataset/test_images/ — Оригинальные фото (тест).
    • data/dataset/train_solution.csv — Оригинальный CSV с метками.
3. Веса (Необходимы для make_diamonds.py):
    • titan_backbone_fold[0-4].pth — Веса backbone от V38.
    • titan_head_fold[0-4].pth — Веса головы от V38.
4. Генерируемые файлы (появятся в процессе):
    • data/faces_512/ — Папка с нарезанными лицами.
    • train_diamond.csv — Новый CSV с псевдо-лейблами.
    • titan_v42_ssl.pth — Веса после SSL.
    • v42_backbone_foldX.pth — Финальные веса.
    • submission_v42.csv — Файл для отправки.

 веса модели: https://drive.google.com/file/d/11nOE_Tibyu1CVBTIN6SoPjwFG0kXNauf/view?usp=sharing

![5](https://github.com/user-attachments/assets/86b288b0-42f0-4f59-a485-072a04772c6b)
![4](https://github.com/user-attachments/assets/d56207ec-bcbe-4e17-a73e-6b5a192d42b9)
![3](https://github.com/user-attachments/assets/9a1a2397-ef88-454b-bd71-97a417e0cc1c)
![2](https://github.com/user-attachments/assets/8ce3d38c-6d96-4aab-8061-0f5216e9e6f9)
![1](https://github.com/user-attachments/assets/d2877698-33d4-49d0-a3f6-cc79f53a275f)



